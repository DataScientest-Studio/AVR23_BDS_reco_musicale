{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e20b8cd1-63e1-48d1-8870-c98fcee7b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9451a6d1-f6fa-47c9-99c1-c226ab4559ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "576b5f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.user_playlist_utils import user_filter, summarise_listening_history\n",
    "from ipynb.fs.full.evaluation_workflow import split_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "942111bb-2d23-49c1-9e98-a79122be56a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_listenings_history_partition(listenings_history_feats, listenings_history, max_clusters = 15, random_state = None):\n",
    "    s_scores = []\n",
    "    labels = []\n",
    "    centroids = []\n",
    "    n_clusters_range = np.arange(2, min(max_clusters, len(listenings_history_feats) - 1))\n",
    "    \n",
    "    # Search the optimal number of clusters\n",
    "    for i in n_clusters_range:\n",
    "        clf = KMeans(n_clusters = i, n_init = \"auto\", random_state = random_state)\n",
    "        clf.fit(listenings_history_feats, sample_weight= listenings_history.listening_count)\n",
    "        centroids.append(clf.cluster_centers_)\n",
    "        labels.append(clf.labels_)\n",
    "        score = silhouette_score(listenings_history_feats, labels[i-2] , metric='euclidean') \n",
    "        s_scores.append(score)\n",
    "    \n",
    "    # Define the optimal number of clusters from the silhouette score\n",
    "    i_clusters_opt = s_scores.index(max(s_scores))\n",
    "    n_cluster_opt = i_clusters_opt +2 \n",
    "\n",
    "    # Return the corresponding partition, \n",
    "    return labels[i_clusters_opt], centroids[i_clusters_opt], s_scores[i_clusters_opt], n_cluster_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0274c7d-a8eb-4531-bf6d-cee8732b3495",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kmeans_based_ranking(listenings_history, X,  weighted = False, n_clusters=\"Default\",  random_state = None):  \n",
    "    \"\"\"\n",
    "    Define the centroid(s) representing the average audio features of the tracks listened by a user.\n",
    "    Estimate the affinity of the user for tracks that he didn't listened based on their distance with this (these) centroid(s).\n",
    "    Return the rank of the unlistened tracks based on this afinity.\n",
    "    \n",
    "    Parameters:\n",
    "        listenings_history (pandas.Dataframe): a dataframe whose columns are\n",
    "            - user : a unique id of the user\n",
    "            \n",
    "            - track_id : a unique id for a track\n",
    "            \n",
    "            - listening_count: the number of times the user has listened to the track\n",
    "            \n",
    "            ... : other columns corresponding to track's features and/or the user's features and/or element of context of the interaction user/track.\n",
    "        \n",
    "        X (pandas.Dataframe): a dataframe corresponding to the audio_features of the tracks.\n",
    "        \n",
    "        weighted (boolean, default = False): determines whether the centroid calculation is weighted by the listens number of the tracks.    \n",
    "         \n",
    "        n_clusters (int or 'auto'): define the number of centroids to form. If 'auto', it is determine as the arg max of the silhouette score.\n",
    "        \n",
    "        \n",
    "        random_state (int, default=None): pass an int for reproducible output across multiple function calls.\n",
    "        \n",
    "    Return :\n",
    "       R : the ranks of each tracks.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the features of the songs listened by the user\n",
    "    listenings_history_feats = X.loc[listenings_history.track_id]      \n",
    "    \n",
    "    \n",
    "    _, _ , _, n_clust_opt =  get_listenings_history_partition(listenings_history_feats, listenings_history, random_state = random_state)\n",
    "    # If a weighting of each tracks is desired :\n",
    "    if weighted:\n",
    "        # Calculation of the weight of each track according to its number of listens\n",
    "        w = listenings_history.listening_count / listenings_history.listening_count.sum()\n",
    "        w.index = listenings_history_feats.index \n",
    "        # Tracks weighting\n",
    "        listenings_history_feats = listenings_history_feats.apply(lambda x: x*w)\n",
    "    \n",
    "    # Compute the user tracks centroids\n",
    "    if n_clusters == 'auto':\n",
    "        labels, centroids, _ ,n_clust_opt = get_listenings_history_partition(listenings_history_feats, listenings_history, random_state = random_state)\n",
    "    elif n_clusters == 1:\n",
    "        labels = np.zeros(len(listenings_history))\n",
    "        centroids = np.array(listenings_history_feats.apply('mean'), ndmin = 2)\n",
    "    elif n_clusters == 'Default':\n",
    "        clf = KMeans(n_clusters = n_clust_opt, n_init = 'auto', random_state = random_state)\n",
    "        clf.fit(listenings_history_feats, sample_weight=listenings_history.listening_count)\n",
    "        centroids = clf.cluster_centers_\n",
    "        labels = clf.labels_\n",
    "    \n",
    "    # Define the number of neighbors to find according to the clusters size\n",
    "    # cluster_size = pd.Series(labels).value_counts()\n",
    "    # nb_tracks_by_clusters = [round(n_neighbors * v) for v in cluster_size / sum(cluster_size)]\n",
    "    # if not sum(nb_tracks_by_clusters) == n_neighbors:\n",
    "    #     nb_tracks_by_clusters[-1] = n_neighbors - sum(nb_tracks_by_clusters[:-1])\n",
    "        \n",
    "    # Compute the distance between the HIDDEN tracks acoustic characteristics (X.index.difference(listenings_history_feats.index)) and the centroids calculated on the APPARENT playlist \n",
    "    D = pd.DataFrame(distance_matrix(X.loc[X.index.difference(listenings_history_feats.index)], centroids), index = X.index.difference(listenings_history_feats.index))           \n",
    "\n",
    "#     # Get the ranks of the tracks as a function of to its distance with each centroid\n",
    "    R = D.rank(axis = 0)\n",
    "\n",
    "#     # Get the n_neighbors unique recommended tracks\n",
    "#     recommended_tracks = []\n",
    "#     for i, n in enumerate(nb_tracks_by_clusters):\n",
    "#         tracks = [t for t in list(R.iloc[:,i].sort_values().index) if not t in recommended_tracks]\n",
    "#         recommended_tracks = recommended_tracks + tracks[:n]\n",
    "\n",
    "    return R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7bbb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_by_artist_filter(initial_ranking, apparent_history: pd.DataFrame):\n",
    "    \n",
    "    initial_ranking.insert(0, 'artist_name', initial_ranking['track_id'].str.split(' - ').str[1])\n",
    "    initial_ranking['min_centroids'] =  np.nan\n",
    "    initial_ranking['artist_rank'] =  np.nan\n",
    "    # get the artists and sort them by proportion in df_user_apparent  \n",
    "    user_artists = (apparent_history.groupby('artist_name')['track_id'].count()/len(apparent_history)).sort_values(ascending=False)\n",
    "\n",
    "\n",
    "    # create a blank df with same columns as user_rank\n",
    "    # calculate the minimum between centroids for each track of artists identified in df_user_apparent\n",
    "    # sort them by this minimum distance\n",
    "    # attribute them a new rank from 1 to len(track_ids) of each artist identifies in order of their importance in df_user_apparent \n",
    "    user_rank_artist = initial_ranking.drop(index = initial_ranking.index, axis=0)\n",
    "    for i, artist in enumerate(user_artists.index):\n",
    "        user_temp = initial_ranking[initial_ranking['artist_name'] == user_artists.index[i]]\n",
    "        user_temp['min_centroids'] = user_temp.iloc[:, 2:-2].min(axis=1)\n",
    "        user_temp = user_temp.sort_values(by='min_centroids')\n",
    "        user_temp['artist_rank'] = user_temp['min_centroids'].rank(method = 'first', ascending=True) + len(user_rank_artist)\n",
    "        user_rank_artist = pd.concat([user_rank_artist,user_temp])\n",
    "\n",
    "\n",
    "    # in original ranking, drop tracks already reranked by artist frequency for artists identified in df_user_apparent\n",
    "    initial_ranking = initial_ranking.drop(user_rank_artist.index)\n",
    "\n",
    "    # sort values of initial ranking by minimum found for each centroid\n",
    "    initial_ranking['min_centroids'] = initial_ranking.iloc[:,2:-2].min(axis=1)\n",
    "    initial_ranking = initial_ranking.sort_values(by='min_centroids')\n",
    "    # attribute them new ranks based on the length of user_rank_artist to get a single rank by track/artist\n",
    "    initial_ranking['artist_rank'] = initial_ranking['min_centroids'].rank(method='first') + len(user_rank_artist)   \n",
    "\n",
    "    # combine new ranking based on artists identified and initial ranks reranked as a continuity of artist based ranks\n",
    "    full_ranks = pd.concat([user_rank_artist, initial_ranking])\n",
    "    full_ranks['best_rank'] = full_ranks.iloc[:, -2:].min(axis=1)\n",
    "\n",
    "    return full_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d14937e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
